<!doctype html>
<html>

<head>
  <title>Reinforcement Learning - Simon Hirlaender</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/base/jquery-ui.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/widgets.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/widgets.js"></script>
<!--  <script src="js/custom.js"></script>-->
  <style>
    .menu-rl {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
        .menu-items li {
      margin: 0 15px;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Advancing Reinforcement Learning</h2>
            <hr>
            <p class="text add-top-margin">
              Reinforcement Learning (RL) stands at the forefront of artificial intelligence, tackling the fundamental challenge of: <br>
              <span class="highlight-text">Learning to make optimal sequences of decisions in complex and uncertain environments.</span><br>
            </p>
            <p class="text">
              My work in RL, leading the <a target="_blank" href="https://www.plus.ac.at/aihi/der-fachbereich/ida-lab/teams/sarl/">Reinforcement Learning Team</a> at the University of Salzburg, is driven by a passion for developing robust and adaptable AI systems. We bridge the gap between theoretical advancements and impactful real-world applications, from enhancing industrial processes with local partners to pioneering new techniques in fundamental research. With a background in physics and control systems, including extensive work at <a target="_blank" href="https://home.cern">CERN</a>, I bring an interdisciplinary approach to tackling some of the most challenging problems in RL.
            </p>

            <h3>Core Research Thrusts &amp; Applications</h3>
            <p class="text">
              Our research activities are diverse, yet interconnected by the common goal of creating more intelligent, reliable, and efficient learning agents. Key areas of focus include:
            </p>
            <ul>
              <li>
                <strong>Sample-Efficient Reinforcement Learning for Continuous Control:</strong>
                Developing methods that can learn effective control policies with minimal data, crucial for physical systems where data collection is expensive or time-consuming. This has direct applications in robotics and automated control systems, such as those found in particle accelerators.
              </li>
              <li>
                <strong>Safe Reinforcement Learning:</strong>
                This is a critical area, ensuring that RL agents operate within specified safety constraints during learning and execution. Our interests here are twofold:
                <ul>
                  <li>Developing sample-efficient methods that inherently respect safety boundaries.</li>
                  <li>Addressing high-stake problems where failures can have significant consequences, including applications in medical treatment planning, critical infrastructure control, and autonomous robotics.</li>
                  <li>Exploring the theoretical underpinnings of safe exploration and exploitation.</li>
                </ul>
              </li>
              <li>
                <strong>Hard Discrete Optimization Problems:</strong>
                Applying RL techniques to find solutions for complex optimization tasks that are computationally challenging for traditional methods, such as logistics, scheduling, and resource allocation.
              </li>
              <li>
                <strong>RL in Physics and Control Systems:</strong>
                 Leveraging my background to apply RL for optimizing and controlling complex physical systems. This includes ongoing collaborations with leading research institutions like CERN (e.g., for projects like AWAKE [[9]](https://inspirehep.net/authors/1651538)), DESY, KIT, and GSI, focusing on areas like particle accelerator operations and experiment control.
              </li>
            </ul>
            <p class="text">
             The ultimate aim is to contribute to the development of AI systems that can learn, adapt, and make sound decisions in the face of real-world complexities, thereby augmenting human capabilities and driving innovation across various scientific and industrial domains.
            </p>
          </div>
        </div>

<!--        <div class="flex-row">-->
<!--          <div class="flex-item flex-item-stretch flex-column">-->
<!--            <p class="text text-small text-italic">-->
<!--              Credits: <span class="highlight-text">IDA Lab</span>: Simon Hirlaender-->
<!--            </p>-->
<!--          </div>-->
<!--        </div>-->
      </div>
    </div>
  </div>
</body>

</html>